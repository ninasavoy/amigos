{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Ridge e Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambos os modelos são técnicas de regressão linear regularizada. A regressão Ridge aplica uma penalização L2, enquanto a Lasso aplica uma penalização L1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando dados\n",
    "np.random.seed(42)\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão dos dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelos Ridge e Lasso\n",
    "ridge = Ridge(alpha=1.0)\n",
    "lasso = Lasso(alpha=0.1)\n",
    "\n",
    "# Treinando os modelos\n",
    "ridge.fit(X_train, y_train)\n",
    "lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predição\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "\n",
    "# Avaliando o desempenho\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "\n",
    "print(f\"MSE Ridge: {mse_ridge:.2f}\")\n",
    "print(f\"MSE Lasso: {mse_lasso:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando os resultados\n",
    "plt.scatter(X_test, y_test, color=\"blue\", label=\"Dados Reais\")\n",
    "plt.plot(X_test, y_pred_ridge, color=\"red\", label=\"Ridge\")\n",
    "plt.plot(X_test, y_pred_lasso, color=\"green\", label=\"Lasso\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.title(\"Regressão Ridge vs Lasso\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ridge e Lasso adicionam uma penalização à função de custo para controlar o ajuste do modelo.\n",
    "- Ridge (L2) reduz os coeficientes, mas não os zera.\n",
    "- Lasso (L1) pode zerar coeficientes, realizando seleção de features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processo de Escolha de Modelo: Validação Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A validação cruzada, como k-fold cross-validation, ajuda a evitar overfitting, dividindo o conjunto de dados em k partes e avaliando o modelo em diferentes subconjuntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de Regressão Linear\n",
    "model = LinearRegression()\n",
    "\n",
    "# Validação Cruzada com 5 folds\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "print(f\"RMSE médio: {rmse_scores.mean():.2f}\")\n",
    "print(f\"Desvio Padrão do RMSE: {rmse_scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Utilizamos cross_val_score com 5 folds para calcular o erro médio.\n",
    "- A métrica utilizada foi o RMSE (Root Mean Squared Error)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métricas de Avaliação: Precisão, Recall e Curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de exemplo\n",
    "y_true = [1, 0, 1, 1, 0, 0, 1, 0, 1, 1]  # Valores reais\n",
    "y_pred = [1, 0, 1, 0, 0, 0, 1, 1, 0, 1]  # Previsões do modelo\n",
    "\n",
    "# Matriz de Confusão\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando Precisão e Recall\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Precisão: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "\n",
    "# Curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plotando a Curva ROC\n",
    "plt.plot(fpr, tpr, color='blue', label=f'AUC = {roc_auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--')\n",
    "plt.xlabel('Taxa de Falsos Positivos (FPR)')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A matriz de confusão mostra os valores de TP, FP, TN e FN.\n",
    "- Precisão é a proporção de verdadeiros positivos em relação ao total de positivos preditos.\n",
    "- Recall é a proporção de verdadeiros positivos em relação ao total de positivos reais.\n",
    "- A Curva ROC mostra a relação entre a taxa de verdadeiros positivos e falsos positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolação e Regressão Logística para Problemas Binários"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos a regressão logística para um exemplo de classificação binária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de exemplo\n",
    "X_binary = np.array([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]])\n",
    "y_binary = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
    "\n",
    "# Modelo de Regressão Logística\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_binary, y_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predição\n",
    "y_pred_log = log_reg.predict(X_binary)\n",
    "accuracy = accuracy_score(y_binary, y_pred_log)\n",
    "\n",
    "print(f\"Acurácia da Regressão Logística: {accuracy:.2f}\")\n",
    "\n",
    "# Plotando a função sigmoide\n",
    "X_range = np.linspace(0, 11, 100).reshape(-1, 1)\n",
    "y_prob = log_reg.predict_proba(X_range)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_range, y_prob, color='green', label='Probabilidade de Classe 1')\n",
    "plt.scatter(X_binary, y_binary, color='blue', label='Dados Reais')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Probabilidade')\n",
    "plt.legend()\n",
    "plt.title('Regressão Logística')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A regressão logística usa a função sigmoide para prever a probabilidade de uma observação pertencer à classe positiva.\n",
    "- O gráfico mostra a curva sigmoide ajustada aos dados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
